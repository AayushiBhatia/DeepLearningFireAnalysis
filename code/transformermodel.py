# -*- coding: utf-8 -*-
"""Copy of TransformerModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lj2RXyNkhmVOUs9PNkoUzTO26iAyYtcl
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import torch
import tensorflow as tf
import random
from torch import nn, optim
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split, ParameterGrid
import matplotlib.pyplot as plt

data = pd.read_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Thailand/Thailand_FC.csv', sep = ',')
data.head()


#data = pd.read_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Malaysia/malaysia-monthly-fc-only.csv')
#data.head()

# data = pd.read_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Indonesia/indonesia-monthly-fc-only.csv')
# data

df = data.copy()
df

df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y')


print(df.head())

# Split data into training and testing sets
train = df[df['DATE'] <= pd.to_datetime('2019-12-31')]
test = df[df['DATE'] > pd.to_datetime('2019-12-31')]

test

scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train['FCSUM'].values.reshape(-1, 1))
test_scaled = scaler.transform(test['FCSUM'].values.reshape(-1, 1))

train_tensor = torch.FloatTensor(train_scaled).view(-1, 1, 1)
test_tensor = torch.FloatTensor(test_scaled).view(-1, 1, 1)

# Define Transformer model
class TransformerModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, nheads, nlayers):
        super(TransformerModel, self).__init__()
        self.input_layer = nn.Linear(input_dim, hidden_dim)
        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nheads, batch_first=True)
        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=nlayers)
        self.decoder = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        x = self.input_layer(x)
        x = self.transformer_encoder(x)
        x = self.decoder(x)
        return x

# Train model
def train_model(model, optimizer, criterion, train_data, epochs):
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(train_data)
        loss = criterion(output, train_data)
        loss.backward()
        optimizer.step()

param_grid = {
    'epochs': [5, 10, 20, 50, 100,  150, 200],
    'learning_rate': [0.0001, 0.001, 0.01],
    'hidden_dim':  [12,16, 32],
    'nheads': [2, 4],
    'nlayers': [1, 2]
}

# Grid search for the best parameters
best_params = None
best_loss = float('inf')

for params in ParameterGrid(param_grid):
    model = TransformerModel(input_dim=1, hidden_dim=params['hidden_dim'], nheads=params['nheads'], nlayers=params['nlayers'])
    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])
    criterion = nn.MSELoss()

    train_model(model, optimizer, criterion, train_tensor, epochs=params['epochs'])


    model.eval()
    with torch.no_grad():
        test_output = model(test_tensor)
        test_loss = criterion(test_output, test_tensor)

    if test_loss < best_loss:
        best_loss = test_loss
        best_params = params

# Print the best parameters
print(f"Best Parameters: {best_params}, Best Loss: {best_loss.item()}")

best_model = TransformerModel(
    input_dim=1,
    hidden_dim=best_params['hidden_dim'],
    nheads=best_params['nheads'],
    nlayers=best_params['nlayers']
)

best_optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])
best_criterion = nn.MSELoss()

# Retrain the model on the entire training set with the best parameters
train_model(best_model, best_optimizer, best_criterion, train_tensor, epochs=best_params['epochs'])

# Evaluate the model on the test set
best_model.eval()
with torch.no_grad():
    test_predictions = best_model(test_tensor)
    test_loss = best_criterion(test_predictions, test_tensor)
    train_predictions = best_model(train_tensor)
    print(f"Test Loss with Best Model: {test_loss.item()}")

# Inverse scale predictions back to the original scale for evaluation
test_predictions_inv = scaler.inverse_transform(test_predictions.squeeze().detach().numpy().reshape(-1, 1))
test_actuals_inv = scaler.inverse_transform(test_tensor.squeeze().detach().numpy().reshape(-1, 1))

# Calculate RMSE for evaluation
rmse = np.sqrt(mean_squared_error(test_actuals_inv, test_predictions_inv))
print(f"RMSE: {rmse}")

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np


mse_test = mean_squared_error(test_actuals_inv, test_predictions_inv)


mae_test = mean_absolute_error(test_actuals_inv, test_predictions_inv)

r2_test = r2_score(test_actuals_inv, test_predictions_inv)

# test_predict = test_predict.flatten()
# y_test = y_test.flatten()

test_rmse = np.sqrt(mean_squared_error(test_actuals_inv, test_predictions_inv))


# Print the results
print(f'MSE (Test): {mse_test}')
print(f'MAE (Test): {mae_test}')
print(f'RÂ² (Test): {r2_test}')
print(f'RMSE (Test): {test_rmse}')

train

train_predictions_inv = scaler.inverse_transform(train_predictions.squeeze().detach().numpy().reshape(-1, 1))
train_actuals_inv = scaler.inverse_transform(train_tensor.squeeze().detach().numpy().reshape(-1, 1))

plt.figure(figsize=(14, 8))
plt.plot(train['DATE'], train_actuals_inv, label='Actual', marker='o')
plt.plot(train['DATE'], train_predictions_inv, label='Fit', marker='x', linestyle = '--')
plt.title('Model Fit Curve')
plt.xlabel('Year')
plt.ylabel('FCSUM')
plt.legend()
plt.grid(False)
plt.show()

plt.figure(figsize=(14, 8))
plt.plot(test['DATE'], test_actuals_inv, label='Actual', marker='o')
plt.plot(test['DATE'], test_predictions_inv, label='Predicted', marker='x', linestyle = '--')
plt.title('Validation Curve')
plt.xlabel('Year')
plt.ylabel('FC')
plt.legend()
plt.grid(False)
plt.show()

plt.figure(figsize=(14, 8))
plt.plot(df['DATE'],df['FCSUM'], label='Actual Data',marker = 'o', color = 'blue' )
plt.plot(train['DATE'], train_predictions_inv, label='Fit Curve', marker='x', linestyle = '--', color = 'orange')
plt.plot(test['DATE'], test_predictions_inv, label='Test Predicted', marker='x',color = 'green')
# plt.title('Transformer Model Predictions')
plt.xlabel('Year')
plt.ylabel('FireCount')
plt.legend()
plt.show()

# plt.figure(figsize=(14, 8))
# plt.plot(df['DATE'],df['FCSUM'], label='Actual Data', color = 'blue' )
# plt.plot(train['DATE'], train_predictions_inv, label='Fit Curve', linestyle = '--', color = 'orange')
# plt.plot(test['DATE'], test_predictions_inv, label='Test Predicted',color = 'green')
# plt.title('Transformer Model Predictions')
# plt.xlabel('Year')
# plt.ylabel('FireCount')
# plt.legend()
# plt.grid(True)
# plt.show()

test_predictions_inv

TransformerResult = pd.DataFrame ({'Date': test.DATE,
                                   'Actual': test_actuals_inv.flatten(),
                                   'Predicted': test_predictions_inv.flatten()})

TransformerResult

TransformerResult.to_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Indonesia/Indo_TransformerResult.csv', index=False)