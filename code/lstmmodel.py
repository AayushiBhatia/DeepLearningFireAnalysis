# -*- coding: utf-8 -*-
"""lstmmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nX3hn7ACN3xPwl_miY5p5yuj43z6dBWH
"""

!pip install scikeras[tensorflow]

pip install tensorflow keras

!pip install --upgrade scikit-learn

import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, GRU, Dense, Dropout
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad, Adamax, Nadam, RMSprop, Ftrl

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import random
from keras.layers import Input, GRU, Dense, Dropout
from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad, Adamax, Nadam, RMSprop, Ftrl
from tensorflow.keras.models import Sequential
from keras.callbacks import EarlyStopping
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.layers import GRU, Dense
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.layers import GRU, Dense, Dropout
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Malaysia/malaysia-monthly-fc-only.csv', sep = ',')
data


# data = pd.read_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Indonesia/indonesia-monthly-fc-only.csv')
# data

df = data.copy()

data['DATE'] = pd.to_datetime(data['DATE'])
data.set_index('DATE', inplace=True)

# Train-test split (train: till Dec 2019, test: after Dec 2019)
train_df = data[:'2019-12']
test_df = data['2020-01':]

# Scaling
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_df)
test_scaled = scaler.transform(test_df)

def create_sequences(data, time_steps=12):
    sequences = []
    labels = []
    for i in range(len(data) - time_steps):
        sequences.append(data[i:i + time_steps])
        labels.append(data[i + time_steps])
    return np.array(sequences), np.array(labels)


def grid_search_lstm(train_data, test_data, param_grid):
    best_score = float('inf')
    best_params = {}
    best_model = None

    for units in param_grid['units']:
        for dropout in param_grid['dropout']:
            for batch_size in param_grid['batch_size']:
                for epochs in param_grid['epochs']:
                    for optimizer in param_grid['optimizer']:
                        for time_steps in param_grid['time_steps']:
                            print(f"Training model with units={units}, dropout={dropout}, batch_size={batch_size}, epochs={epochs}, optimizer={optimizer}, time_steps={time_steps}")


                            X_train, y_train = create_sequences(train_data, time_steps)
                            X_test, y_test = create_sequences(test_data, time_steps)


                            X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
                            X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

                            # LSTM model
                            model = Sequential()
                            model.add(Input(shape=(time_steps, 1)))
                            model.add(LSTM(units, return_sequences=True))
                            model.add(Dropout(dropout))
                            model.add(LSTM(units, return_sequences=False))
                            model.add(Dropout(dropout))
                            model.add(Dense(1))

                            model.compile(optimizer=optimizer, loss='mean_squared_error')


                            model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

                            test_predictions = model.predict(X_test)


                            test_predictions = test_predictions.reshape(-1, 1)
                            y_test = y_test.reshape(-1, 1)

                            test_predictions = scaler.inverse_transform(test_predictions)
                            y_test_true = scaler.inverse_transform(y_test)


                            rmse = np.sqrt(mean_squared_error(y_test_true, test_predictions))

                            if rmse < best_score:
                                best_score = rmse
                                best_params = {
                                    'units': units,
                                    'dropout': dropout,
                                    'batch_size': batch_size,
                                    'epochs': epochs,
                                    'optimizer': optimizer,
                                    'time_steps': time_steps
                                }
                                best_model = model

    return best_model, best_params, best_score

param_grid = {
    'units': [50, 100],
    'dropout': [0.2, 0.3],
    'batch_size': [32, 64],
    'epochs': [50, 100],
    'optimizer': ['adam', 'rmsprop'],
    'time_steps': [12, 24]
}

# Perform grid search
best_model, best_params, best_score = grid_search_lstm(train_scaled, test_scaled, param_grid)

# Output the best hyperparameters
print("Best parameters:", best_params)
print("Best RMSE:", best_score)

X_train, y_train = create_sequences(train_scaled, best_params['time_steps'])
X_test, y_test = create_sequences(test_scaled, best_params['time_steps'])

X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))


train_predictions = best_model.predict(X_train)
test_predictions = best_model.predict(X_test)

train_predictions = scaler.inverse_transform(train_predictions.reshape(-1, 1))
y_train_true = scaler.inverse_transform(y_train.reshape(-1, 1))
test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))
y_test_true = scaler.inverse_transform(y_test.reshape(-1, 1))


predicted_full = np.concatenate([train_predictions, test_predictions], axis=0)
actual_full = np.concatenate([y_train_true, y_test_true], axis=0)


full_index = pd.concat([train_df[best_params['time_steps']:], test_df[best_params['time_steps']:]])

# Evaluation metrics
rmse = np.sqrt(mean_squared_error(y_test_true, test_predictions))
mae = mean_absolute_error(y_test_true, test_predictions)
mse = mean_squared_error(y_test_true, test_predictions)
r2 = r2_score(y_test_true, test_predictions)

print(f"Test RMSE: {rmse}")
print(f"Test MAE: {mae}")
print(f"Test MSE: {mse}")
print(f"Test RÂ²: {r2}")

train_predictions = best_model.predict(X_train)
test_predictions = best_model.predict(X_test)

train_predictions_rescaled = scaler.inverse_transform(train_predictions)
test_predictions_rescaled = scaler.inverse_transform(test_predictions)


y_train_true = scaler.inverse_transform(y_train.reshape(-1, 1))
y_test_true = scaler.inverse_transform(y_test.reshape(-1, 1))

plt.figure(figsize=(14, 8))

# Plot full actual data
plt.plot(data.index, data['FCSUM'], color='blue', label='Actual Data', marker = 'o')

# Plot train predictions
plt.plot(train_df.index[best_params['time_steps']:], train_predictions, color='orange', label='Fit Curve', linestyle = '--', marker = 'x')

# Plot test predictions
plt.plot(test_df.index[best_params['time_steps']:], test_predictions, color='green', label='Test Predictions', marker = 'x')

# Add labels, title, and legend
plt.title('Actual vs Predicted FCSUM (Train and Test)')
plt.xlabel('Date')
plt.ylabel('FCSUM')
plt.legend()

# Show the plot
plt.show()

test_predictions

test_predictions_rescaled = scaler.inverse_transform(test_predictions)
y_test_true_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))


LSTMResults = pd.DataFrame({
    'Date': test_df.index[best_params['time_steps']:],
    'Predicted': test_predictions.flatten()
})


LSTMResults.set_index('Date', inplace=True)


print(LSTMResults)

LSTMResults.to_csv('/content/drive/MyDrive/NSSTC/DeepLearning/SEAsiaGRU/Thailand/LSTMResults1.csv', index=True)